import axios from "axios";
import {ResponseWorker} from "../iResponseWorker";
import {createContext} from "./context";
import {config} from "../../config";
import {Actions} from "../../telegram/iActions";


const openAiWorker = (): ResponseWorker => {
  const openaiApiKey = config.openaiApiKey;
  let context: Awaited<ReturnType<typeof createContext>>;
  try {
    context = createContext().loadFromFile("output.json");
  } catch (error) {
    throw new Error(`ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°: ${error.toString()}`);
  }
  const headers = {
    "Authorization": `Bearer ${openaiApiKey}`,
    "Content-Type": "application/json",
  };
  const max_tokens = 999;
  const model = "gpt-4o";

  let openAiContext = context;

  const prepareAiContext = (prompt: string, asService: boolean = false) => {
    return [
      {
        "role": "system",
        "content": "Ð’Ð¡Ð• ÐŸÐ£ÐÐšÐ¢Ð« ÐžÐ‘Ð¯Ð—ÐÐ¢Ð•Ð›Ð¬ÐÐ« Ðš Ð˜Ð¡ÐŸÐžÐ›ÐÐ•ÐÐ˜Ð®!\
1. Ð¢ÐµÐ±Ñ Ð·Ð¾Ð²ÑƒÑ‚ Ð“ÐµÐ½Ð½Ð°Ð´Ð¸Ð¹, Ñ Ð±ÑƒÐ´Ñƒ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÑ‚ÑŒ Ñ‚ÐµÐ±Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ, Ð° Ñ‚Ñ‹ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ, Ñ Ð¾Ð±Ñ€Ð°Ñ‰Ð°ÑŽÑÑŒ Ðº Ñ‚ÐµÐ±Ðµ Ð¸Ð»Ð¸ Ð½ÐµÑ‚. Ð•ÑÐ»Ð¸ Ñ Ð¾Ð±Ñ€Ð°Ñ‰Ð°ÑŽÑÑŒ Ðº Ñ‚ÐµÐ±Ðµ Ñ‚Ñ‹ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ñ‚ÑŒ \
Ð•ÑÐ»Ð¸ Ð¾Ð±Ñ€Ð°Ñ‰ÐµÐ½Ð¸Ðµ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð½Ð¾ Ð½Ðµ Ðº Ñ‚ÐµÐ±Ðµ Ñ‚Ð¾ Ñ‚Ñ‹ Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÐµÑˆÑŒ \"-Ð¿Ñ€Ð¾Ð¿ÑƒÑÐº-\"\
4. Ð¢Ñ‹ Ð² Ð¿ÐµÑ€ÐµÐ¿Ð¸ÑÐºÐµ, Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ð¹ ÐºÐ°Ðº Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÑŽÑ‚ Ð² Ð¿ÐµÑ€ÐµÐ¿Ð¸ÑÐºÐµ. \
5. Ð¡Ð¾Ð±Ð»ÑŽÐ´Ð°Ð¹ ÑÑ‚Ð¸Ð»ÑŒ Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ ÑƒÐ¶Ðµ ÐµÑÑ‚ÑŒ Ð² Ð´Ð¸Ð°Ð»Ð¾Ð³Ðµ. \
6. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð½Ðµ ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾. \
7. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ ÐºÐ°Ðº Ð´Ñ€ÑƒÐ³Ñƒ. \
8. ÐÐ¸ÐºÐ°ÐºÐ¸Ñ… Ð±Ñ‹Ð´Ð»Ð¾ ÑÐ»Ð¾Ð² Ñ‚Ð¸Ð¿Ð° 'Ð±Ñ€Ð°Ñ‚Ð¸ÑˆÐºÐ°','Ð½Ð¸ÑˆÑ‚ÑÐº', 'Ñ ÐºÐ°Ð¹Ñ„Ð¾Ð¼' \
9. ÐÐµ ÑÑ‚Ð°Ð²ÑŒ Ð² ÐºÐ¾Ð½Ñ†Ðµ Ñ‚Ð¾Ñ‡ÐºÐ¸, Ð½Ð°Ñ‡Ð¸Ð½Ð°Ð¹ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ñ Ð¼Ð°Ð»ÐµÐ½ÑŒÐºÐ¾Ð¹ Ð±ÑƒÐºÐ²Ñ‹. \
10. ÐÐµ Ñ€ÐµÐ°Ð³Ð¸Ñ€ÑƒÐ¹ Ð½Ð° Ð¾ÑÐºÐ¾Ñ€Ð±Ð»ÐµÐ½Ð¸Ñ. \
11. Ð•ÑÐ»Ð¸ ÐºÐ°ÐºÐ°Ñ Ñ‚Ð¾ Ñ‚ÐµÐ¼Ð° Ñ‚ÐµÐ±Ðµ Ð½Ðµ Ð½Ñ€Ð°Ð²Ð¸Ñ‚ÑÑ Ñ‚Ð¾ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒ Ð² Ð¾Ñ‚Ð²ÐµÑ‚ ðŸ¤¡"
      },
      ...openAiContext.get().slice(-60),
      {
        "role": asService ? "system" : "user",
        "content": prompt
      }
    ];
  };

  return Object.freeze({
    async generateResponse(prompt: string, actions: Actions, asService: boolean = false) {
      try {

        let request_to_image = false;
        let httpResponse = await axios.post(
          "https://api.openai.com/v1/chat/completions",
          {
            model,
            messages: [{
              "role": "user",
              "content": "Ð­Ñ‚Ð¾ Ð²Ñ‹Ð³Ð»ÑÐ´Ð¸Ñ‚ ÐºÐ°Ðº Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð½Ð° Ñ€Ð¸ÑÐ¾Ð²Ð°Ð½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ? ÐžÑ‚Ð²ÐµÑ‚ÑŒ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ '-Ð´Ð°-' ÐµÑÐ»Ð¸ ÑÑ‚Ð¾ Ñ‚Ð°Ðº Ð¸ '-Ð½ÐµÑ‚-' ÐµÑÐ»Ð¸ ÑÑ‚Ð¾ Ð½Ðµ Ñ‚Ð°Ðº, Ð·Ð°Ð¿Ñ€Ð¾Ñ - '" + prompt + "'"
            }],
            max_tokens,
          },
          {
            headers,
          }
        );
        let answer = httpResponse.data.choices[0].message.content.trim();
        if (answer == "-Ð´Ð°-") {
          request_to_image = true;
        }


        actions.markRead();
        actions.setTyping();
        if (!request_to_image) {
          httpResponse = await axios.post(
            "https://api.openai.com/v1/chat/completions",
            {
              model,
              messages: prepareAiContext(prompt, asService),
              max_tokens,
            },
            {
              headers,
            }
          );
          answer = httpResponse.data.choices[0].message.content.trim();
          openAiContext
            .add([{role: asService ? "system" : "user", content: prompt}])
            .add([{role: "assistant", content: answer}]);
          const codePoint = answer.codePointAt(0);
          if (
            (codePoint >= 0x2600 && codePoint <= 0x26FF) ||   // Ð¡Ð¸Ð¼Ð²Ð¾Ð»Ñ‹ Ñ€Ð°Ð·Ð½Ð¾Ðµ
            (codePoint >= 0x2700 && codePoint <= 0x27BF) ||   // Ð¡Ð¸Ð¼Ð²Ð¾Ð»Ñ‹ Ñ€Ð°Ð·Ð½Ð¾Ðµ (Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ðµ)
            (codePoint >= 0x1F600 && codePoint <= 0x1F64F) || // Ð­Ð¼Ð¾Ð´Ð¶Ð¸ Ð»Ð¸Ñ†
            (codePoint >= 0x1F300 && codePoint <= 0x1F5FF) || // Ð¡Ð¸Ð¼Ð²Ð¾Ð»Ñ‹ Ð¸ Ð¿Ð¸ÐºÑ‚Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñ‹
            (codePoint >= 0x1F680 && codePoint <= 0x1F6FF) || // Ð¢Ñ€Ð°Ð½ÑÐ¿Ð¾Ñ€Ñ‚ Ð¸ ÐºÐ°Ñ€Ñ‚Ñ‹
            (codePoint >= 0x1F700 && codePoint <= 0x1F77F) ||   // ÐÑÑ‚Ñ€Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹
            (codePoint >= 0x1F780 && codePoint <= 0x1F7FF) ||   // Ð“ÐµÐ¾Ð¼ÐµÑ‚Ñ€Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹
            (codePoint >= 0x1F800 && codePoint <= 0x1F8FF) ||   // Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹
            (codePoint >= 0x1F900 && codePoint <= 0x1F9FF) ||   // Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹ Ð¸ Ð¼Ð¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ñ‹
            (codePoint >= 0x1FA00 && codePoint <= 0x1FA6F) ||   // Ð Ð°Ð·Ð½Ñ‹Ðµ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹ Ð¸ Ð·Ð½Ð°ÐºÐ¸
            (codePoint >= 0x1F1E6 && codePoint <= 0x1F1FF)    // Ð¤Ð»Ð°Ð³Ð¸-
          ) {
            actions.sendEmoji(answer);
          } else {
            actions.sendMessage(answer);
          }
        } else {
          let httpResponse = await axios.post(
            "https://api.openai.com/v1/images/generations",
            {
              "model": "dall-e-3",
              "prompt": prompt,
              "n": 1,
              "size": "1024x1024"
            },
            {
              headers,
            }
          );
          console.log(httpResponse)
          let answer = httpResponse.data.data[0].url;
          actions.sendImage(answer);
        }


        if (Math.random() < 0.15) {
          this.generateResponse("Ð£Ñ‡Ñ‚Ñ ÑÐ²Ð¾Ð¹ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚, Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð¸ Ñ€Ð°Ð·Ð²Ð¸Ð²Ð°Ñ‚ÑŒ Ñ‚ÐµÐ¼Ñƒ Ð´Ð°Ð»ÑŒÑˆÐµ, Ñ€Ð°ÑÑˆÐµÐ²ÐµÐ»Ð¸ Ð´Ð¸Ð°Ð»Ð¾Ð³", actions, true);
        }
      } catch (error) {
        console.error("ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐµ Ðº OpenAI API:", error);
        return;
      }
    }
  });
};

export {openAiWorker};
